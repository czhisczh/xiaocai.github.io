# Data Assistant 1.0

> 因为工作需求，平时需要反复接触同类型的数据，有各种平台上去拉取，基本上关键数据到手里都是都是excel的形式。

## 常见需求包括：
1. 【计算文本】经计算后的数据在合适位置填入基本固定的文本，形成分析概况；
2. 【表格图片】经常见的计算范式得到固定格式的报表，目前的需求来看，最终需求基本是图片格式；
3. 【生成洞察】对各项指标的历史数据全局分析，或结合用户提供相关背景情况，输出整体的情况分析和数据洞察；
4. 【个人述职】结合日常记录输出精简的个人周度工作报告；
5. 【数据下拆】对常见的数据下拆工作支持可视化的操作步骤

## 预估想法
1. 关于数据源的处理，设计每次运行需要选择excel表格文件不可行，缺点有每次运行需要导入文件很麻烦，最重要的是历史数据的理解运用对计划中的后续版本开发很重要。目前的想法是用PostgreSQL管理历史数据库，用相应的MCP组件链接数据库和data assistant，做到支持对数据的精确调用、理解、操作。
2. 上一点或许主要是对数据的管理，对数据的处理操作目前的想法有两个：1、一个是【Link1】的拆建，【Link1】是MCP组件，它的逻辑应该是提供了一些方法（nodejsORpython的）在通过大模型的function call或者系统提示词来选择组件里提供的某个方法，来执行相应的针对于数据库的操作，已知地至少可以调用数据，能不能准确地操作还不是很清楚，我想PostgreSQL应该可以支持，如果走得通，会引伸到权限设计的问题；2、或者就是数据库就是数据库，数据计算就是数据计算，把需要的数据拿出来用pandas库操作
3. 还有一个整体设计上的卡点就是，关于类似【表格图片】和整体数据处理需求，是比较个性化的，即使在行业运营的组内，数据源、指标选择、【计算文本】尚且有不同，对表格的美术要求也是经常会需要更新的，作为一个处理型的工具，对于输出格式、指标选择、计算过程恰到好处的用户自定义能力很重要。用户的自定义能力赋予得越少，适用性越差，赋予得越多，操作越麻烦，需要平衡。
4. 上面这个卡点解决之后，界面设计差不多也就完成了
5. 我想上面几个卡点如果可以顺利解决，data assistant 1.0 差不多就可以打包上线了。剩下的基本上是一些体验方面的设计。今天先记录到这里，后续的具体想法、进度、问题、设计后续再慢慢更新吧。


**取名**
简单点吧，叫data assistant
## 链接
【1】https://github.com/modelcontextprotocol/servers/tree/main/src/postgres